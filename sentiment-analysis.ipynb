{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Kaggle API in Visual Studio Code\n",
    "\n",
    "## Overview\n",
    "The Kaggle API allows you to interact with the Kaggle platform from the command line. This guide will cover installing the Kaggle API and navigating directories in Visual Studio Code.\n",
    "\n",
    "## Installation\n",
    "\n",
    "### 1. Install the Kaggle API\n",
    "First, you need to install the Kaggle API using pip. Open the terminal in Visual Studio Code and run:\n",
    "\n",
    "```bash\n",
    "pip install kaggle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading `kaggle.json` for Kaggle API\n",
    "\n",
    "## Overview\n",
    "To use the Kaggle API, you need to authenticate with your Kaggle account. This is done using a `kaggle.json` file, which contains your API credentials. This guide explains how to download the `kaggle.json` file from the Kaggle website.\n",
    "\n",
    "## Steps to Download `kaggle.json`\n",
    "\n",
    "### 1. Log in to Kaggle\n",
    "First, go to the [Kaggle website](https://www.kaggle.com) and log in to your account.\n",
    "\n",
    "### 2. Navigate to Your Account\n",
    "Click on your profile picture in the top right corner of the page, then select \"My Account\" from the dropdown menu.\n",
    "\n",
    "### 3. Create a New API Token\n",
    "Scroll down to the \"API\" section. Click on the \"Create New API Token\" button. This action will generate a new `kaggle.json` file containing your API credentials.\n",
    "\n",
    "### 4. Download `kaggle.json`\n",
    "The `kaggle.json` file will be automatically downloaded to your computer. This file contains your username and API key in JSON format.\n",
    "\n",
    "### 5. Secure `kaggle.json`\n",
    "For security reasons, ensure that your `kaggle.json` file is kept private. Do not share it with others or upload it to public repositories.\n",
    "\n",
    "## Setting Up `kaggle.json`\n",
    "\n",
    "### 1. Locate Your Downloaded File\n",
    "Find the `kaggle.json` file in your computer's Downloads folder or the location where your browser saves downloaded files.\n",
    "\n",
    "### 2. Place `kaggle.json` in the Correct Directory\n",
    "\n",
    "Move the `kaggle.json` file to the following directory:\n",
    "```bash\n",
    "D:\\Dokumen\\2024\\Tutorial\\ML-engineer\\Twitter Sentiment Analysis\" \n",
    "```\n",
    "(since i want the kaggle.json is the same place as my main code)\n",
    "\n",
    "### 3. Set the KAGGLE_CONFIG_DIR to the directory where 'kaggle.json' is located\n",
    "```bash\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = \"D:\\Dokumen\\2024\\Tutorial\\ML-engineer\\Twitter Sentiment Analysis\"\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Sentiment Dataset\n",
    "\n",
    "### Downloading a dataset\n",
    "API to fetch the dataset from Kaggle\n",
    "```bash\n",
    "kaggle datasets download -d kazanova/sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bisa ni gan datanya\n"
     ]
    }
   ],
   "source": [
    "#extracting the compressed dataset\n",
    "\n",
    "from zipfile import ZipFile\n",
    "dataset = 'sentiment140.zip'\n",
    "\n",
    "with ZipFile(dataset, 'r') as zip:\n",
    "    zip.extractall()\n",
    "    print('bisa ni gan datanya')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\asust\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data from csv file to pandas dataframe\n",
    "tweets_data = pd.read_csv('2009-tweets.csv', encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599999, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking gthe number of rows and columns\n",
    "tweets_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweets_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# printing point head of csv.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtweets_data\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tweets_data' is not defined"
     ]
    }
   ],
   "source": [
    " # printing point head of csv.\n",
    "\n",
    "tweets_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
